# Crawler-Selenium-Screenshot
 The script crawls through (max 50) urls of a page and crawls further. The code then visits the immediate URLS (assuming the usual navigation bar nature), grabs a screenshot (full page) and stores them in a folder.

Output process
![alt text](https://github.com/kanishk307/Crawler-Selenium-Screenshot/blob/master/Output/OutputInJupyter.png?raw=true)

Folder containing Screenshots
![alt text](https://github.com/kanishk307/Crawler-Selenium-Screenshot/blob/master/Output/ImgsInFolder.png?raw=true)

Inputs that need to be provided : Base URL (eg: https://umd.edu/virusinfo OR https://www.ucf.edu/coronavirus)

You can run the python file as it is (with required imports). I think it is interactive to run the python notebook.
